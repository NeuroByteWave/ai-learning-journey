# ğŸ“˜ Introduction to Generative AI (Google Cloud)
Presenter: Roger Martinez, Developer Relations Engineer at Google Cloud
Purpose: Understand what Generative AI is, how it works, and how it is applied.

## ğŸ¤– What Is Generative AI?
Generative AI (GenAI) is a type of artificial intelligence that can create contentâ€”such as:

Text

Images

Audio

Synthetic data

Code

Video

GenAI models are trained on large datasets and generate new content based on learned patterns.

## ğŸ“š Foundations: AI vs. ML vs. DL
ğŸ§© **Artificial Intelligence (AI)**
A discipline of computer science focused on building systems that mimic human intelligence.

Includes reasoning, learning, acting autonomously.

ğŸ§  **Machine Learning (ML)**
A subset of AI that enables systems to learn from data rather than explicit programming.

Produces models that generalize from training data.

âš™ï¸ **Types of ML**
Supervised Learning: Uses labeled data. Model learns relationships between input (X) and output (Y).

Example: Predicting tips based on order type and bill total.

Unsupervised Learning: Uses unlabeled data to find patterns (e.g., clustering).

Example: Grouping employees based on tenure and income.

Semi-supervised Learning: Uses a mix of labeled + unlabeled data. Common in neural networks.

ğŸ§  **Deep Learning (DL)**
A subset of ML using Artificial Neural Networks (ANNs) with multiple layers (deep networks).

Learns complex features.

Inspired by the human brain.

## ğŸ§ª Generative vs. Discriminative Models
Type	Description	Example Output
Discriminative	Classifies input data (predicts label y given x).	Spam/Not Spam
Generative	Learns full data distribution (P(x, y)) and generates new data.	Text, images, etc.

Example:

Discriminative: Classifies a picture as a dog.

Generative: Creates a new image of a dog.

ğŸ“ˆ **Traditional vs. Generative AI Workflows**
ğŸ—ï¸ **Traditional ML:**
Inputs: Training code + labeled data.

Outputs: Classification, prediction, clustering.

## ğŸ¨ Generative AI:
Inputs: Training code + labeled & unlabeled data.

Output: New content (text, image, code, etc.)

Built on foundation models.

ğŸ§¾ **Mathematical Framing**
Y = f(X) â†’ Output is a function of inputs.

If Y is a number/class â†’ traditional ML.

If Y is text/image/audio â†’ it's Generative AI.

ğŸ›ï¸ **Foundation Models**
Large pre-trained models adaptable to many downstream tasks:

Text: Chat, summarization, sentiment analysis

Vision: Image captioning, object detection

Multimodal: Text + image/video/audio

ğŸ’¡ **Googleâ€™s Gemini and LaMDA are examples.**

## ğŸ“¦ Types of Generative Models (Text Input)
Model Type	Description
Text-to-Text	Input text â†’ Output text (e.g. translation, summarization)
Text-to-Image	Input text â†’ Output image (e.g. diffusion models like Stable Diffusion)
Text-to-Video	Input text â†’ Output video
Text-to-3D	Input text â†’ Output 3D model
Text-to-Task	Input text â†’ Task execution (e.g. UI automation, doc editing)

## ğŸ› ï¸ Real-World Applications
ğŸ”¤ **Language & Text**
Chatbots, email generation, documentation

Sentiment analysis

Text summarization

ğŸ§‘â€ğŸ’» **Code Generation**
Convert code formats (e.g., Pandas DataFrame â†’ JSON)

Debug or complete code

Generate API documentation

ğŸ¨ **Vision**
Image generation from text (Stable Diffusion)

Object recognition (e.g., occupancy analytics)

ğŸ’¼ **Industry Use Cases**
Healthcare: diagnostics, summarization

Finance: fraud detection

Retail: recommendation systems

Customer service: chatbots, virtual agents

ğŸ§ª **Transformers: The Backbone of GenAI**
Introduced in 2017/2018, revolutionizing NLP.

Components:

Encoder: Encodes input

Decoder: Predicts output

Core to LLMs (e.g., Gemini, GPT)

## âš ï¸ Hallucinations
Nonsensical or incorrect model outputs

Caused by:

Limited or noisy training data

Poor context

Lack of constraints

## ğŸ§  Prompt Engineering
Prompt = Input to LLM to control output.

Prompt design = Crafting effective inputs to guide desired model behavior.

## ğŸ§© Summary: What is Generative AI?
Generative AI is a branch of AI that uses deep learning to create new content based on patterns learned from existing data.

Core Characteristics:
Learns from existing content

Outputs novel content

Uses foundation models

Fueled by transformer architecture

