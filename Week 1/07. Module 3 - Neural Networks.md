# Machine Learning

Neural networks are a part of a larger discipline callend **Machine Learning**, whose goal is to use data to train computer models that are able to solve problems.
In Machine Learning, we assume that we have some dataset of examples X, and corresponding output values Y. Examples are often N-dimensional vectors that consist of features, and outputs are called labels.

**Two most common machine learning problems:**
  - Classification: we need to classify an input object into two or more classes
  - Regression: we need to predict a numerical number for each of the input samples


## Perceptron

**Perceptron** - is the simplest type of artificial neural network, inspired by how neurons work in the brain. It’s basically a decision-making machine that takes input, processes it, and gives an output — like answering "yes" or "no" to a question.
Python code for training Perceptron:

## Multi-Layered Perceptron

**Formalization of Machine Learning**

**Machine Learning (ML)** is a field of study where we teach machines to learn from data and make predictions or decisions without being explicitly programmed.

Let's start with formalizing the Machine Learning problem. Suppose we have a training dataset X with labels Y, and we need to build a model f that will make most accurate predictions. The quality of predictions is measured by Loss function ℒ. The following loss functions are often used:

 - For regression problem, when we need to predict a number, we can use absolute error ∑i|f(x(i))-y(i)|, or squared error ∑i(f(x(i))-y(i))2
 - For classification, we use 0-1 loss (which is essentially the same as accuracy of the model), or logistic loss.
For one-level perceptron, function f was defined as a linear function f(x)=wx+b (here w is the weight matrix, x is the vector of input features, and b is bias vector). For different neural network architectures, this function can take more complex form.

**Gradient Descent Optimization**

There is a well-known method of function optimization called gradient descent. The idea is that we can compute a derivative (in multi-dimensional case called gradient) of loss function with respect to parameters, and vary parameters in such a way that the error would decrease. This can be formalized as follows:

Initialize parameters by some random values w(0), b(0)
Repeat the following step many times:
w(i+1) = w(i)-η∂ℒ/∂w
b(i+1) = b(i)-η∂ℒ/∂b
During training, the optimization steps are supposed to be calculated considering the whole dataset (remember that loss is calculated as a sum through all training samples). However, in real life we take small portions of the dataset called minibatches, and calculate gradients based on a subset of data. Because subset is taken randomly each time, such method is called stochastic gradient descent (SGD).

**Multi-Layered Perceptrons and backpropagation**

One-layer network, as we have seen above, is capable of classifying linearly separable classes. To build a richer model, we can combine several layers of the network. Mathematically it would mean that the function f would have a more complex form, and will be computed in several steps:

z1=w1x+b1
z2=w2α(z1)+b2
f = σ(z2)
Here, α is a non-linear activation function, σ is a softmax function, and parameters θ=<w1,b1,w2,b2>.

The gradient descent algorithm would remain the same, but it would be more difficult to calculate gradients. Given the chain differentiation rule, we can calculate derivatives as:

∂ℒ/∂w2 = (∂ℒ/∂σ)(∂σ/∂z2)(∂z2/∂w2)
∂ℒ/∂w1 = (∂ℒ/∂σ)(∂σ/∂z2)(∂z2/∂α)(∂α/∂z1)(∂z1/∂w1)

## Neural Network Frameworks

**What We Need to Train Neural Networks**
To train a neural network well, we need two main things:

  - **Work with Tensors** – Do math stuff (like adding, multiplying) and use functions (like sigmoid or softmax) on tensors (fancy arrays of numbers).

  - **Compute Gradients** – Figure out how much to tweak the model to make it better (gradient descent).

**Numpy** can handle the math, but it doesn’t do gradients automatically.

In the past, we had to code all the gradient calculations ourselves (like in the backward method). A good framework should do this for us.

**Why GPUs Matter**
Training big neural networks takes a ton of calculations.

GPUs (or TPUs) speed things up by doing many calculations at once (parallelizing).

A good framework should let us use GPUs easily.

**Popular Frameworks: TensorFlow vs. PyTorch**

Both do similar things but in slightly different ways:
________________________________________
Level	        TensorFlow	    PyTorch
________________________________________
Low-Level	    TensorFlow	    PyTorch
________________________________________
High-Level	  Keras	PyTorch   Lightning
________________________________________

  - Low-Level API: Gives you full control. You build a computational graph (a roadmap for how data flows and gets       processed). Good for research or custom models.

  - High-Level API: Makes life easier. Just stack layers like Lego blocks and call fit() to train. Best for standard neural networks.

You can mix both—use high-level for most things but drop into low-level when you need more control.

## Overfitting – When Your Model is "Memorizing" Instead of "Learning"

**Imagine fitting a curve to some points:**
  - Good Fit (Left): A simple line that captures the trend. Fewer parameters → generalizes well.
  - Overfit (Right): A super complex curve that hits every point but fails on new data. Too many parameters → memorizes noise instead of learning the real pattern.

**Why Overfitting Happens**
  1. **Not enough training data** → Model memorizes instead of generalizing.
  2. **Model is too powerful** → Too many parameters for the data.
  3. **Noisy data** → Model learns the noise instead of the real pattern.

**How to Spot Overfitting:**
  - **Training error** keeps dropping (even to near zero).
  - **Validation error** starts rising after a point.
  - **Graph hint:** If validation error goes up while training error goes down → Overfitting!

**How to Stop Overfitting**
  1. Get more training data (if possible).
  2. Simplify the model (fewer layers/parameters).
  3. Use regularization (like Dropout, which we’ll cover later).

**Bias vs. Variance Tradeoff**
  - **Bias (Underfitting):** Model is too simple → Can’t learn well.
  - **Variance (Overfitting):** Model is too complex → Memorizes noise.
  - **Goal:** Find the sweet spot where the model learns the pattern without overcomplicating things.
